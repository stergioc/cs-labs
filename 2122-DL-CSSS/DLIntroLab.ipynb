{"cells":[{"cell_type":"markdown","metadata":{"id":"c4Gur7SBm4Ao"},"source":["<table>\n","<td height=\"150px\">\n","<img src='https://stergioc.github.io/assets/img/logos.png' />\n","</td>\n","</table>\n","\n","<h1>Introduction to Deep Learning (Hands-on Session)</h1>\n","<h3>Stergios CHRISTODOULIDIS</h3>"]},{"cell_type":"markdown","metadata":{"id":"hYPer61thgVY"},"source":["# 1. Introduction\n","\n","In this tutorial a short introduction on some core functionalities of the [tensorflow](https://www.tensorflow.org/) deep learning libary will be introduced. Other libraries like [pytorch](https://pytorch.org/) or [jax](https://jax.readthedocs.io/en/latest/index.html) can offer similar functionalities. All libraries have interfaces with other programing languages making it easy to integrate in different pipelines.\n","\n","The main features of tensorflow:\n","- GPU/TPU backends\n","- computational graphs\n","- differentiable programing -> forward and backward computation functions implemented\n","- optimization algorithms\n","- data loading\n","- different levels of abstractions (from simple functions to complete models e.g. [keras](https://keras.io/))\n","\n","## Session Overview\n","\n","1. Preparing the work environment (remote servers, python environment, tensorflow package installed, colab)\n","2. Core Tensorflow Functionalities. (Variables definition and gradiets calculation)\n","2. Data preparation (in house data, publily available data, combination) -> Data loader (input-output pairs)\n","3. Model definition (MLP, CNN), or out-of-the-self models selection (AlexNet, ResNet, GoogleNet, etc.)\n","4. Training scheme (train/val/test sets), batch size, optimizer (SGD, Adam), learning rate\n","5. Training\n","5. Performance evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xZcitNWwhs3w"},"outputs":[],"source":["# Importing the necessary libaries\n","import os                       # operating system functionality\n","import uuid                     # unique random number generator\n","import tensorflow as tf         # Tensorflow\n","\n","import numpy as np              # Multi-Dimentional Array Management\n","import matplotlib.pyplot as plt # Plotting functionality\n","\n","# This is used in order to show the plotted figures within this notebook\n","%matplotlib inline \n","# This is used in order to show the tensorboard within this notebook             \n","%load_ext tensorboard           "]},{"cell_type":"markdown","metadata":{"id":"-iuDctig_LZz"},"source":["# 2. Low Level Tensorflow Operations\n","\n","Tensorflow provides ways to design complicated mathematical models using graph structures and also functions to easily calculate gradients on these models with respect to some variable.\n","\n","Let's try to create the following model:\n","\n","![simple_unit](https://res.cloudinary.com/practicaldev/image/fetch/s--7y0EX4vc--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/DrakeEntity/project-Image/master/1_8VSBCaqL2XeSCZQe_BAyVA.jpeg)\n","\n","Then we can calculate the gradients of the MSE loss:\n","\n","$$ \\operatorname{MSE}=\\frac{1}{n}\\sum_{i=1}^n(Y_i-\\hat{Y_i})^2. $$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztv_o0YVASho"},"outputs":[],"source":["# Define a pairs of input (e.g. m=3) and output\n","# x = ...\n","# y = ...\n","# Define all the rest components of the model using tf.Variable (https://www.tensorflow.org/api_docs/python/tf/Variable)\n","# The loss function can be defined with the help of tf.reduce_mean (https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean)"]},{"cell_type":"markdown","metadata":{"id":"W3cm4iNMsea8"},"source":["# 3. Data Loading\n","\n","On this tutorial we will be using publicly available data and we will focus on classification tasks. You can choose one of the following datasets:\n","\n","- MNIST (greyscale image hand written digit classification)\n","- Fashion-MNIST (greuscale image garment classification)\n","- CIFAR10 (RGB image classification)\n","\n","Typically such dataset are coming in a predefined split (train/test)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AkY0rsGv3Oc"},"outputs":[],"source":["# Loads a database (you can choose any one, cifar10 is in RGB)\n","#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","\n","print('[Initial] x_train shape:', x_train.shape, ' - ', '[Initial] x_test shape:', x_test.shape)\n","print('[Initial] y_train shape:', y_train.shape, ' - ', '[Initial] y_test shape:', y_test.shape)\n","\n","# Plot an example from the training set\n","\n","# Bring X input data in the range between 0. and 1.\n","\n","# Convert the Y class vector (integers) to binary class matrix (you can use keras utility function to_categorical)\n","\n","# Add a singleton dimension at the end if grayscale dataset (samples, width, height, 1)\n","# If cifar10 there already three channel dimentions at the end (RBG)\n","\n","print('[final] x_train shape:', x_train.shape, ' - ', '[final] x_test shape:', x_test.shape)\n","print('[final] y_train shape:', y_train.shape, ' - ', '[final] y_test shape:', y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"mSsm3mELUGF4"},"source":["# 4. Multilayer Perceptron (MLP)\n","\n","Let's now move on to a bit more complicated model such as a multilayer perceptron with e.g. 64 hidden units.\n","\n","![mlp](https://austingwalters.com/wp-content/uploads/2018/12/mlp.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PUV0eyDVrwG"},"outputs":[],"source":["# Edit the following linear logistic regression model and change it to an MLP\n","inp = tf.keras.Input(shape=x_train.shape[1:])             # Defines an input layer\n","x = tf.keras.layers.Flatten()(inp)                        # This layer flattens the input to a single dimension\n","out = tf.keras.layers.Dense(10, activation='softmax')(x)  # This adds a fully connected layer at the end that applies also a softmax operation\n","\n","mlp = tf.keras.Model(inputs=inp, outputs=out, name='MLP') # builds the model object\n","mlp.summary()                                             # prints out a summary of the final model"]},{"cell_type":"markdown","metadata":{"id":"3m_ICVIRUlDS"},"source":["# 5. Model Compilation and Training\n","\n","In this part we will compile the above model define some of the learning parameters and train it for a few epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dX-3LTMCc5bM"},"outputs":[],"source":["%tensorboard --logdir logs # Loads the tensorboar platform for the visualization of the model training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aLHP31bIUvNN"},"outputs":[],"source":["# use the Model.compile function to compile the defined model (https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile)\n","\n","alias = 'MLP'+ '-' + str(uuid.uuid4())    # Creates a unique string for the particular model\n","logdir = os.path.join(\"logs\", alias)      # Creates the directory name to save the model results \n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1) # Tensorboard callback for visualization\n","\n","# Use the Model.fit to train the model (https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)\n","# mlp.fit(..., callbacks=[tensorboard_callback])"]},{"cell_type":"markdown","metadata":{"id":"o8jngSCnyL8I"},"source":["# 6. Convolutional Neural Network\n","\n","Edit and expand the previous model and change it to the LeNet architecture. You can also try different activations functions or number of filters.\n","\n","![LeNet](https://cdn-images-1.medium.com/max/800/1*lvvWF48t7cyRWqct13eU0w.jpeg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z12fcJzmyZhH"},"outputs":[],"source":["# Implement a Convolutional Neural Network with the following architecture\n","#1 -> Convolutional layer with 6 kernels and tanh activation function\n","#2 -> Max pooling downsampling the image by 2\n","#3 -> Convolutional layer with 16 kernels and tanh activation function\n","#4 -> Max pooling downsampling the image by 2\n","#5 -> Flatten layer\n","#6 -> Fully connected layer with 120 units\n","#7 -> Fully connected layer with 84 units\n","#8 -> Fully connected layer with 10 units\n","\n","# Conv2D (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n","# MaxPool2D (https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)\n","# Flatten (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n","# Dense (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)"]},{"cell_type":"markdown","metadata":{"id":"WI7U4qIgU3q-"},"source":["# 7. Training Evaluation\n","\n","The learning curves and testing results are calculated and presented"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4mJ27LXBU6qk"},"outputs":[],"source":["# Calcualte the network's predictions on the test set and prints the confusion matrix\n","\n","# Use model predict function (https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict)\n","\n","# Use the confusion_matrix function of tf (https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMv1xhIhzaISERDiDfI/lkp","collapsed_sections":[],"name":"CS AI Summer School 21 - Introduction to Deep Learning Hands-on.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
